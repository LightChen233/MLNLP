{
  "session_name": "Session 6: 代码大模型 <span style=\"white-space: pre;word-break: break-word;\"> (9月1日 15:50-17:50) </span>",
  "session_chair": "论坛主席：刘乾 (Sea AI Lab)  &nbsp;&nbsp;&nbsp;&nbsp; 王焱林 (中山大学)",
  "session_desc": "本次论坛将聚焦于大型语言模型在代码领域的前沿研究。四位来自工业界和学术界的代码大模型专家将深入探讨大模型在代码处理中的能力，涵盖的主题包括通过减少数据截断提升代码补全性能、让模型学会理解代码执行过程、新一代针对代码生成的测试基准，以及代码大模型背后技术的深度解析。本论坛旨在通过这些讨论，促进对代码大模型及其广泛应用的深入理解。",
  "session_time": [
    "15:50",
    "17:50"
  ],
  "apple": "data:text/calendar;charset=utf8,BEGIN:VCALENDAR%0AVERSION:2.0%0ABEGIN:VTIMEZONE%0ATZID:Asia/Shanghai%0AX-LIC-LOCATION:Asia/Shanghai%0ABEGIN:STANDARD%0ATZOFFSETFROM:+0800%0ATZOFFSETTO:+0800%0ATZNAME:CST%0ADTSTART:19700101T000000%0AEND:STANDARD%0AEND:VTIMEZONE%0ABEGIN:VEVENT%0AURL:%0ADTSTART;TZID=Asia/Shanghai:20230924T155000%0ADTEND;TZID=Asia/Shanghai:20230924T175000%0ATZID:Asia/Shanghai%0ASUMMARY:%5BMLNLP%202023%5D%20Session%206%20代码大模型%0ADESCRIPTION:注册链接：https://event.baai.ac.cn/event/705 论坛简介：本次论坛将聚焦于大型语言模型在代码领域的前沿研究。四位来自工业界和学术界的代码大模型专家将深入探讨大模型在代码处理中的能力，涵盖的主题包括通过减少数据截断提升代码补全性能、让模型学会理解代码执行过程、新一代针对代码生成的测试基准，以及代码大模型背后技术的深度解析。本论坛旨在通过这些讨论，促进对代码大模型及其广泛应用的深入理解。%0ALOCATION:%0ABEGIN:VALARM%0ATRIGGER:-PT10M%0AACTION:DISPLAY%0ADESCRIPTION:Reminder%0AEND:VALARM%0ALOCATION:http://www.mlnlp.world/mlnlp2023/%0AEND:VEVENT%0AEND:VCALENDAR",
  "google": "https://calendar.google.com/calendar/r/eventedit?dates=20230924T155000%2F20230924T175000&text=%5BMLNLP%202023%5D%20Session%206%20代码大模型&details=注册链接：https://event.baai.ac.cn/event/705 论坛简介：本次论坛将聚焦于大型语言模型在代码领域的前沿研究。四位来自工业界和学术界的代码大模型专家将深入探讨大模型在代码处理中的能力，涵盖的主题包括通过减少数据截断提升代码补全性能、让模型学会理解代码执行过程、新一代针对代码生成的测试基准，以及代码大模型背后技术的深度解析。本论坛旨在通过这些讨论，促进对代码大模型及其广泛应用的深入理解。&ctz=Asia%2FShanghai&location=http://www.mlnlp.world/mlnlp2023/",
  "outlook": "https://outlook.live.com/owa?rru=addevent&startdt=2023-09-24T15:50:00&enddt=2023-09-24T17:50:00&subject=%5BMLNLP%202023%5D%20Session%206%20代码大模型&body=注册链接：https://event.baai.ac.cn/event/705 论坛简介：本次论坛将聚焦于大型语言模型在代码领域的前沿研究。四位来自工业界和学术界的代码大模型专家将深入探讨大模型在代码处理中的能力，涵盖的主题包括通过减少数据截断提升代码补全性能、让模型学会理解代码执行过程、新一代针对代码生成的测试基准，以及代码大模型背后技术的深度解析。本论坛旨在通过这些讨论，促进对代码大模型及其广泛应用的深入理解。&allday=false&path=%2Fcalendar%2Fview%2FMonth&location=http://www.mlnlp.world/mlnlp2023/",
  "session_slido_url": "https://app.sli.do/event/e2tALxHWFLNpQTYZb8dnso",
  "session_list": [
    {
      "time": [
        "15:50",
        "16:20"
      ],
      "speaker": {
        "img": "assets/img/speakers/wangzijian.png",
        "name": "王子健",
        "desc": "亚马逊云科技人工智能实验室 / Amazon Q Developer团队技术主管经理",
        "url": "https://zijianwang.me/"
      },
      "type": "专题报告",
      "title": "在预训练中减少数据截断以提升大模型性能",
      "slides": "",
      "recoding": "",
      "desc": "在大语言模型的预训练中，传统的拼接分块方法会导致文档截断，影响模型对上下文的理解和生成内容的一致性。为解决这一问题，本次报告将介绍“最佳适配打包”（Best-fit Packing）策略，通过优化文档组合，消除了所有不必要的截断，从而显著提升了模型性能。实验结果显示，这一方法在众多自然语言和程序语言的任务中都现优异，并显著减少了尤其在代码补全任务上的闭域幻觉现象，进一步提高了模型的可靠性和实用性。"
    },
    {
      "time": [
        "16:20",
        "16:50"
      ],
      "speaker": {
        "img": "assets/img/speakers/niansong.png",
        "name": "倪安松",
        "desc": "Meta AI – FAIR研究科学家",
        "url": "https://niansong1996.github.io/"
      },
      "type": "专题报告",
      "title": "让大模型学会理解代码执行",
      "slides": "",
      "recoding": "",
      "desc": "大模型在自动代码生成方面取得了卓越的成效，但只在代码本身上面训练却并不能让它们完全理解代码在运行的时候的执行逻辑，这导致了他们对于一些复杂的任务仍难以取得较高的准确率。本报告将介绍如何让大模型学会理解代码执行的两个工作。首先将介绍NExT，一种提高大模型对于程序执行推理的自训练方法。NExT通过不断的生成和执行代码并利用代码执行轨迹（Execution Trace）来训练大模型理解程序运行并生成自然语言的思维链（Chain-of-Thought）和程序员用户进行沟通。另外，本报告还将介绍LEVER，一种从程序执行结果中学习如何验证程序正确性的方法。LEVER无需微调大模型本身，而只需训练一个小模型来对大模型的生成结果进行再排序，以此来提高总体的正确率。"
    },
    {
      "time": [
        "16:50",
        "17:20"
      ],
      "speaker": {
        "img": "assets/img/speakers/zhuoyue.png",
        "name": "卓越",
        "desc": "莫纳什大学博士 / 澳大利亚联邦科学与工业研究组织研究工程师",
        "url": ""
      },
      "type": "专题报告",
      "title": "BigCodeBench: 新一代大模型代码生成基准与评测生态",
      "slides": "",
      "recoding": "https://terryyz.github.io/",
      "desc": "本报告将详细介绍新一代代码生成基准测试 BigCodeBench 的发展与应用。BigCodeBench 是一个旨在评估大语言模型代码生成能力的基准测试，通过模拟真实软件开发需求和复杂指令的编程任务，全面测试模型的性能。该基准测试包含由 BigCode 社区成员共同构建的超过一千个编程任务，涵盖约140个常用库，横跨多个应用领域。 BigCodeBench 提供了一个完整且透明的评估框架，并设有实时更新的评测榜单，广受社区和多家知名大模型开发企业的关注和支持。其评测生态系统已逐渐成为为数不多的主流代码生成基准测试之一。 此外，本报告将探讨 BigCodeBench 的可持续发展生态，包括其未来的开发路线和近期成果。通过不断更新和完善，BigCodeBench 致力于推动大语言模型在代码生成领域的进步，为研究人员和开发者提供一个可靠的评测工具和平台。"
    },
    {
      "time": [
        "17:20",
        "17:50"
      ],
      "speaker": {
        "img": "assets/img/speakers/huibinyuan.png",
        "name": "惠彬原",
        "desc": "阿里巴巴通义实验室研究员",
        "url": "https://huybery.github.io/l"
      },
      "type": "专题报告",
      "title": "Code with CodeQwen",
      "slides": "",
      "recoding": "",
      "desc": "CodeQwen是Qwen开源体系中的专有代码模型。CodeQwen通过可自动的数据清洗、可扩展的数据合成、可预测的训练策略等方式，在代码生成、长序列代码理解、代码修复、SQL生成等能力上实现了先进的效果。同时，CodeQwen一直致力于「实用的开源模型」，在代码补全和代码智能体上也做了深入的探索，为基础能力和实际应用能力的共同进步提供了新的思路。"
    }
  ]
}